#!/usr/bin/env python3
"""
Doc Converter - æ‰¹é‡æ–‡æ¡£è½¬ Markdown å·¥å…·

ä½¿ç”¨ markitdown å°†åŠå…¬æ–‡æ¡£ï¼ˆPDFã€PPTã€Wordã€Excel ç­‰ï¼‰æ‰¹é‡è½¬æ¢ä¸º Markdownï¼Œ
ç”Ÿæˆ CSV ç´¢å¼•ä¾› Claude åç»­åˆ†æã€æ‘˜è¦å’Œæ€ç»´å¯¼å›¾åˆ†ç±»ã€‚
"""

import argparse
import csv
import json
import os
import sys
from dataclasses import dataclass, field
from datetime import datetime
from pathlib import Path
from typing import Optional


# æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
SUPPORTED_EXTENSIONS = {
    ".pdf", ".pptx", ".docx", ".xlsx", ".xls",
    ".csv", ".html", ".htm", ".epub",
    ".json", ".xml",
}

# æ‰«ææ—¶æ’é™¤çš„ç›®å½•
EXCLUDED_DIRS = {
    ".git", ".svn", ".hg",
    ".cache", ".npm", ".yarn", ".pnpm",
    ".venv", "venv", "env", ".env",
    "__pycache__", ".pytest_cache",
    "node_modules", "vendor", "packages",
    "Library", ".Trash",
    ".idea", ".vscode", ".vs",
    "build", "dist", "target", "out",
    ".summaries",
}


@dataclass
class DocInfo:
    """æ–‡æ¡£ä¿¡æ¯"""
    original_path: str
    file_type: str
    file_size: int
    file_size_human: str = ""
    markdown_path: str = ""
    conversion_status: str = "pending"
    error_message: str = ""
    converted_at: str = ""


@dataclass
class ConvertReport:
    """è½¬æ¢æŠ¥å‘Š"""
    scan_time: str
    source_paths: list = field(default_factory=list)
    documents: list = field(default_factory=list)
    total_files: int = 0
    total_size_bytes: int = 0
    total_size_human: str = ""
    converted_count: int = 0
    failed_count: int = 0
    summaries_dir: str = ""


def format_size(size_bytes: int) -> str:
    """æ ¼å¼åŒ–æ–‡ä»¶å¤§å°"""
    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:
        if size_bytes < 1024:
            return f"{size_bytes:.1f} {unit}"
        size_bytes /= 1024
    return f"{size_bytes:.1f} PB"


def check_markitdown() -> bool:
    """æ£€æŸ¥ markitdown æ˜¯å¦å·²å®‰è£…"""
    try:
        import markitdown  # noqa: F401
        return True
    except ImportError:
        return False


class DocConverter:
    """æ–‡æ¡£æ‰¹é‡è½¬æ¢å™¨"""

    def __init__(self, paths: list[str]):
        self.paths = [os.path.expanduser(p) for p in paths]
        self.documents: list[DocInfo] = []

    def _should_exclude(self, path: Path) -> bool:
        """æ£€æŸ¥æ˜¯å¦åº”è¯¥æ’é™¤è¯¥è·¯å¾„"""
        for part in path.parts:
            if part in EXCLUDED_DIRS:
                return True
        return False

    def _get_summaries_dir(self) -> str:
        """è·å– .summaries è¾“å‡ºç›®å½•ï¼ˆåŸºäºç¬¬ä¸€ä¸ªè·¯å¾„ï¼‰"""
        first = Path(self.paths[0])
        if first.is_file():
            base = first.parent
        else:
            base = first
        return str(base / ".summaries")

    def scan(self) -> list[DocInfo]:
        """æ‰«ææ‰€æœ‰è·¯å¾„ï¼Œæ”¶é›†æ”¯æŒçš„æ–‡æ¡£"""
        self.documents = []

        for path_str in self.paths:
            path = Path(path_str)

            if not path.exists():
                print(f"  âš ï¸  è·¯å¾„ä¸å­˜åœ¨: {path_str}")
                continue

            if path.is_file():
                self._add_file(path)
            elif path.is_dir():
                self._scan_dir(path)

        # æŒ‰æ–‡ä»¶å¤§å°é™åºæ’åº
        self.documents.sort(key=lambda d: d.file_size, reverse=True)
        return self.documents

    def _scan_dir(self, directory: Path):
        """é€’å½’æ‰«æç›®å½•"""
        try:
            for item in sorted(directory.iterdir()):
                if item.is_dir():
                    if item.name.startswith(".") or item.name in EXCLUDED_DIRS:
                        continue
                    self._scan_dir(item)
                elif item.is_file():
                    self._add_file(item)
        except PermissionError:
            print(f"  âš ï¸  æ— æƒé™è®¿é—®: {directory}")

    def _add_file(self, path: Path):
        """æ·»åŠ å•ä¸ªæ–‡ä»¶"""
        ext = path.suffix.lower()
        if ext not in SUPPORTED_EXTENSIONS:
            return

        try:
            size = path.stat().st_size
        except OSError:
            return

        doc = DocInfo(
            original_path=str(path),
            file_type=ext,
            file_size=size,
            file_size_human=format_size(size),
        )
        self.documents.append(doc)

    def preview(self, use_json: bool = False) -> ConvertReport:
        """é¢„è§ˆæ¨¡å¼ï¼šåˆ—å‡ºå°†è¦è½¬æ¢çš„æ–‡æ¡£"""
        if not self.documents:
            self.scan()

        report = ConvertReport(
            scan_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            source_paths=self.paths,
            documents=self.documents,
            total_files=len(self.documents),
            total_size_bytes=sum(d.file_size for d in self.documents),
            summaries_dir=self._get_summaries_dir(),
        )
        report.total_size_human = format_size(report.total_size_bytes)

        if use_json:
            print(json.dumps({
                "scan_time": report.scan_time,
                "source_paths": report.source_paths,
                "total_files": report.total_files,
                "total_size": report.total_size_human,
                "summaries_dir": report.summaries_dir,
                "documents": [
                    {
                        "path": d.original_path,
                        "type": d.file_type,
                        "size": d.file_size_human,
                        "size_bytes": d.file_size,
                    }
                    for d in self.documents
                ],
            }, indent=2, ensure_ascii=False))
        else:
            print(f"ğŸ“‚ æ‰«æè·¯å¾„: {', '.join(self.paths)}")
            print(f"ğŸ“Š æ‰¾åˆ° {report.total_files} ä¸ªæ–‡æ¡£, å…± {report.total_size_human}")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {report.summaries_dir}")
            print("")

            # æŒ‰æ–‡ä»¶ç±»å‹åˆ†ç»„ç»Ÿè®¡
            by_type: dict[str, list[DocInfo]] = {}
            for doc in self.documents:
                by_type.setdefault(doc.file_type, []).append(doc)

            type_icons = {
                ".pdf": "ğŸ“„", ".pptx": "ğŸ“Š", ".docx": "ğŸ“",
                ".xlsx": "ğŸ“ˆ", ".xls": "ğŸ“ˆ", ".csv": "ğŸ“ˆ",
                ".html": "ğŸŒ", ".htm": "ğŸŒ", ".epub": "ğŸ“š",
                ".json": "ğŸ“‹", ".xml": "ğŸ“‹",
            }

            for ext, docs in sorted(by_type.items(), key=lambda x: -len(x[1])):
                icon = type_icons.get(ext, "ğŸ“„")
                total_size = sum(d.file_size for d in docs)
                print(f"  {icon} {ext}: {len(docs)} ä¸ª, {format_size(total_size)}")

            if self.documents:
                print("")
                print("ğŸ“‹ æ–‡ä»¶åˆ—è¡¨:")
                for i, doc in enumerate(self.documents, 1):
                    icon = type_icons.get(doc.file_type, "ğŸ“„")
                    name = Path(doc.original_path).name
                    print(f"  {i:3d}. {icon} {name} ({doc.file_size_human})")

        return report

    def convert(self, use_json: bool = False) -> ConvertReport:
        """æ‰§è¡Œè½¬æ¢"""
        if not self.documents:
            self.scan()

        if not self.documents:
            print("â„¹ï¸  æ²¡æœ‰å¯è½¬æ¢çš„æ–‡æ¡£")
            return ConvertReport(
                scan_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                source_paths=self.paths,
            )

        # æ£€æŸ¥ markitdown
        if not check_markitdown():
            print("âŒ markitdown æœªå®‰è£…")
            print("   è¯·è¿è¡Œ: pip install 'markitdown[all]'")
            sys.exit(1)

        from markitdown import MarkItDown

        md_converter = MarkItDown()

        # åˆ›å»ºè¾“å‡ºç›®å½•
        summaries_dir = self._get_summaries_dir()
        converted_dir = os.path.join(summaries_dir, "converted")
        briefs_dir = os.path.join(summaries_dir, "briefs")
        os.makedirs(converted_dir, exist_ok=True)
        os.makedirs(briefs_dir, exist_ok=True)

        report = ConvertReport(
            scan_time=datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            source_paths=self.paths,
            documents=self.documents,
            total_files=len(self.documents),
            total_size_bytes=sum(d.file_size for d in self.documents),
            summaries_dir=summaries_dir,
        )
        report.total_size_human = format_size(report.total_size_bytes)

        if not use_json:
            print(f"ğŸ”„ å¼€å§‹è½¬æ¢ {report.total_files} ä¸ªæ–‡æ¡£...")
            print(f"ğŸ“ è¾“å‡ºç›®å½•: {summaries_dir}")
            print("")

        for i, doc in enumerate(self.documents, 1):
            name = Path(doc.original_path).stem
            ext = doc.file_type
            md_filename = f"{name}{ext}.md"
            md_path = os.path.join(converted_dir, md_filename)

            if not use_json:
                print(f"  [{i}/{report.total_files}] è½¬æ¢: {Path(doc.original_path).name}...", end=" ")

            try:
                result = md_converter.convert(doc.original_path)
                content = result.text_content if result.text_content else ""

                with open(md_path, "w", encoding="utf-8") as f:
                    f.write(f"# {name}\n\n")
                    f.write(f"> åŸå§‹æ–‡ä»¶: {doc.original_path}\n")
                    f.write(f"> æ–‡ä»¶ç±»å‹: {ext} | å¤§å°: {doc.file_size_human}\n")
                    f.write(f"> è½¬æ¢æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
                    f.write("---\n\n")
                    f.write(content)

                doc.markdown_path = md_path
                doc.conversion_status = "success"
                doc.converted_at = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
                report.converted_count += 1

                if not use_json:
                    print("âœ…")

            except Exception as e:
                doc.conversion_status = "failed"
                doc.error_message = str(e)
                report.failed_count += 1

                if not use_json:
                    print(f"âŒ {e}")

        # ç”Ÿæˆ CSV ç´¢å¼•
        csv_path = os.path.join(summaries_dir, "index.csv")
        self._write_csv(csv_path)

        if use_json:
            print(json.dumps({
                "scan_time": report.scan_time,
                "source_paths": report.source_paths,
                "total_files": report.total_files,
                "total_size": report.total_size_human,
                "converted": report.converted_count,
                "failed": report.failed_count,
                "summaries_dir": summaries_dir,
                "index_csv": csv_path,
                "documents": [
                    {
                        "original_path": d.original_path,
                        "markdown_path": d.markdown_path,
                        "file_type": d.file_type,
                        "size": d.file_size_human,
                        "status": d.conversion_status,
                        "error": d.error_message,
                    }
                    for d in self.documents
                ],
            }, indent=2, ensure_ascii=False))
        else:
            print("")
            print(f"âœ… è½¬æ¢å®Œæˆ: {report.converted_count} æˆåŠŸ, {report.failed_count} å¤±è´¥")
            print(f"ğŸ“„ CSV ç´¢å¼•: {csv_path}")
            print(f"ğŸ“ Markdown æ–‡ä»¶: {converted_dir}")
            print(f"ğŸ“ æ‘˜è¦ç›®å½•ï¼ˆå¾… Claude ç”Ÿæˆï¼‰: {briefs_dir}")

        return report

    def _write_csv(self, csv_path: str):
        """å†™å…¥ CSV ç´¢å¼•"""
        fieldnames = [
            "original_path", "markdown_path", "file_type",
            "file_size", "conversion_status", "error_message", "converted_at",
        ]

        with open(csv_path, "w", encoding="utf-8-sig", newline="") as f:
            writer = csv.DictWriter(f, fieldnames=fieldnames)
            writer.writeheader()
            for doc in self.documents:
                writer.writerow({
                    "original_path": doc.original_path,
                    "markdown_path": doc.markdown_path,
                    "file_type": doc.file_type,
                    "file_size": doc.file_size,
                    "conversion_status": doc.conversion_status,
                    "error_message": doc.error_message,
                    "converted_at": doc.converted_at,
                })


def main():
    parser = argparse.ArgumentParser(
        description="Doc Converter - æ‰¹é‡æ–‡æ¡£è½¬ Markdown å·¥å…·",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  %(prog)s ~/Documents/reports --preview          # é¢„è§ˆæ–‡æ¡£åˆ—è¡¨
  %(prog)s ~/Documents/reports --convert --confirm # æ‰§è¡Œè½¬æ¢
  %(prog)s file1.pdf file2.pptx --convert --confirm # è½¬æ¢æŒ‡å®šæ–‡ä»¶
  %(prog)s ~/Documents --preview --json            # JSON æ ¼å¼é¢„è§ˆ

æ”¯æŒæ ¼å¼: .pdf, .pptx, .docx, .xlsx, .xls, .csv, .html, .epub, .json, .xml
        """
    )

    parser.add_argument("paths", nargs="+", help="æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„")
    parser.add_argument("--preview", action="store_true", help="é¢„è§ˆæ¨¡å¼ï¼Œåˆ—å‡ºæ–‡æ¡£")
    parser.add_argument("--convert", action="store_true", help="æ‰§è¡Œè½¬æ¢")
    parser.add_argument("--confirm", action="store_true", help="ç¡®è®¤æ‰§è¡Œï¼ˆå®‰å…¨æœºåˆ¶ï¼‰")
    parser.add_argument("--json", action="store_true", help="JSON æ ¼å¼è¾“å‡º")

    args = parser.parse_args()

    if not args.preview and not args.convert:
        parser.print_help()
        return

    converter = DocConverter(args.paths)

    if args.preview:
        converter.preview(use_json=args.json)
        return

    if args.convert:
        if not args.confirm:
            print("âŒ è½¬æ¢éœ€è¦ --confirm å‚æ•°ç¡®è®¤")
            print("   è¯·å…ˆä½¿ç”¨ --preview é¢„è§ˆï¼Œç¡®è®¤åæ·»åŠ  --confirm æ‰§è¡Œè½¬æ¢")
            return

        # å…ˆæ£€æŸ¥ markitdown
        if not check_markitdown():
            print("âŒ markitdown æœªå®‰è£…")
            print("   è¯·è¿è¡Œ: pip install 'markitdown[all]'")
            sys.exit(1)

        converter.convert(use_json=args.json)


if __name__ == "__main__":
    main()
